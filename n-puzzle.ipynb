{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions â€” see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from heapq import heappop, heappush\n",
    "from random import choice\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Solvability check\n",
    "def is_solvable(state: np.ndarray) -> bool:\n",
    "    flat_state = state.flatten()\n",
    "    flat_state = flat_state[flat_state != 0]  # Exclude the empty tile\n",
    "    inversions = sum(1 for i in range(len(flat_state)) for j in range(i + 1, len(flat_state)) if flat_state[i] > flat_state[j])\n",
    "    if PUZZLE_DIM % 2 == 1:\n",
    "        return inversions % 2 == 0\n",
    "    else:\n",
    "        empty_row = PUZZLE_DIM - np.where(state == 0)[0][0]\n",
    "        return (inversions + empty_row) % 2 == 0\n",
    "    \n",
    "# Create a solvable puzzle from a non solvable one\n",
    "def make_solvable(state: np.ndarray) -> np.ndarray:\n",
    "    flat_state = state.flatten()\n",
    "    flat_state = flat_state[flat_state != 0]  # Exclude the empty tile\n",
    "    inversions = sum(1 for i in range(len(flat_state)) for j in range(i + 1, len(flat_state)) if flat_state[i] > flat_state[j])\n",
    "    empty_row = PUZZLE_DIM - np.where(state == 0)[0][0]\n",
    "    if inversions % 2 == 0:\n",
    "        flat_state[-2], flat_state[-1] = flat_state[-1], flat_state[-2]\n",
    "    else:\n",
    "        flat_state[-3], flat_state[-4] = flat_state[-4], flat_state[-3]\n",
    "    new_state = state.copy()\n",
    "    new_state[new_state != 0] = flat_state\n",
    "    return new_state\n",
    "\n",
    "    def search(state, g, threshold, path):\n",
    "        \"\"\"Performs a bounded search up to the given threshold.\"\"\"\n",
    "        f = g + heuristic(state, goal_state)\n",
    "        if f > threshold:\n",
    "            return f, None\n",
    "        if np.array_equal(state, goal_state):\n",
    "            return True, path\n",
    "\n",
    "        min_threshold = float('inf')\n",
    "        for act in available_actions(state):\n",
    "            next_state = do_action(state, act)\n",
    "            if len(path) > 0 and path[len(path) - 1].pos1 == act.pos2:\n",
    "                continue  # Avoid undoing the last move\n",
    "            new_g = g + 1\n",
    "            result, new_path = search(next_state, new_g, threshold, path + [act])\n",
    "            if result is True:\n",
    "                return True, new_path\n",
    "            if result < min_threshold:\n",
    "                min_threshold = result\n",
    "\n",
    "        return min_threshold, None\n",
    "\n",
    "    threshold = heuristic(initial_state, goal_state)\n",
    "    while True:\n",
    "        result, path = search(initial_state, 0, threshold, [])\n",
    "        if result is True:\n",
    "            return path\n",
    "        if result == float('inf'):\n",
    "            return \"No solution found.\"\n",
    "        threshold = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various heuristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan distance heuristic\n",
    "def manhattan(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    distance = 0\n",
    "    for i in range(PUZZLE_DIM):\n",
    "        for j in range(PUZZLE_DIM):\n",
    "            value = state[i, j]\n",
    "            if value != 0:\n",
    "                target_x, target_y = divmod(np.where(goal == value)[0][0], PUZZLE_DIM)\n",
    "                distance += abs(i - target_x) + abs(j - target_y)\n",
    "    return distance\n",
    "\n",
    "def hamming(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    return np.sum(state != goal) - 1  # Exclude the empty tile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def linear_conflict_manhattan(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    def linear_conflict(state, goal):\n",
    "        \"\"\"Compute linear conflicts.\"\"\"\n",
    "        conflict_count = 0\n",
    "        # Check rows\n",
    "        for row in range(PUZZLE_DIM):\n",
    "            tiles_in_row = [state[row, col] for col in range(PUZZLE_DIM) if state[row, col] != 0]\n",
    "            goal_positions = {tile: divmod(np.where(goal == tile)[0][0], PUZZLE_DIM)[1] for tile in tiles_in_row}\n",
    "            for i, tile1 in enumerate(tiles_in_row):\n",
    "                for tile2 in tiles_in_row[i + 1:]:\n",
    "                    if goal_positions[tile1] > goal_positions[tile2]:\n",
    "                        conflict_count += 1\n",
    "        # Check columns\n",
    "        for col in range(PUZZLE_DIM):\n",
    "            tiles_in_col = [state[row, col] for row in range(PUZZLE_DIM) if state[row, col] != 0]\n",
    "            goal_positions = {tile: divmod(np.where(goal == tile)[0][0], PUZZLE_DIM)[0] for tile in tiles_in_col}\n",
    "            for i, tile1 in enumerate(tiles_in_col):\n",
    "                for tile2 in tiles_in_col[i + 1:]:\n",
    "                    if goal_positions[tile1] > goal_positions[tile2]:\n",
    "                        conflict_count += 1\n",
    "        return 2 * conflict_count  # Each conflict adds 2 moves\n",
    "\n",
    "    # Combine Manhattan distance and linear conflict\n",
    "    return manhattan(state, goal) + linear_conflict(state, goal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A*  or Dijkstra's search\n",
    "\n",
    "def search_astar(initial_state: np.ndarray, goal_state: np.ndarray, heuristic, use_heuristic: bool = True):\n",
    "    \"\"\"\n",
    "    Unified search algorithm for A* and Dijkstra's based on the use_heuristic flag.\n",
    "    \n",
    "    Args:\n",
    "        initial_state (np.ndarray): Initial puzzle state.\n",
    "        goal_state (np.ndarray): Goal puzzle state.\n",
    "        use_heuristic (bool): If True, uses A*; if False, uses Dijkstra's algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        list: Sequence of actions leading to the goal state, or an error message if unsolvable.\n",
    "    \"\"\"\n",
    "    if not is_solvable(initial_state):\n",
    "        return \"Puzzle is not solvable.\"\n",
    "\n",
    "    visited = set()\n",
    "    priority_queue = []\n",
    "    heappush(priority_queue, (0, 0, initial_state.tobytes(), []))  # (priority, cost, state, path)\n",
    "    steps = 0\n",
    "\n",
    "    while priority_queue:\n",
    "        _, cost, current_state_bytes, path = heappop(priority_queue)\n",
    "        current_state = np.frombuffer(current_state_bytes, dtype=initial_state.dtype).reshape(initial_state.shape)\n",
    "\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            #print cost and steps\n",
    "            print(f\"Steps: {steps}, Cost: {cost}\")\n",
    "            return path\n",
    "\n",
    "        visited.add(current_state_bytes)\n",
    "\n",
    "        for act in available_actions(current_state):\n",
    "            new_state = do_action(current_state, act)\n",
    "            new_state_bytes = new_state.tobytes()\n",
    "            if new_state_bytes not in visited:\n",
    "                new_cost = cost + 1\n",
    "                # Priority is cost + heuristic for A*, or just cost for Dijkstra's\n",
    "                priority = new_cost + (heuristic(new_state, goal_state) if use_heuristic else 0)\n",
    "                heappush(priority_queue, (priority, new_cost, new_state_bytes, path + [act]))\n",
    "\n",
    "        steps += 1\n",
    "        if steps % 100_000 == 0:\n",
    "            print(f\"Steps: {steps}, Cost: {cost}\")\n",
    "        if steps > 1_000_000:\n",
    "            #Print solution and return\n",
    "            print(\"Final state: \\n\", current_state)\n",
    "            print(f\"Steps: {steps}, Cost: {cost}\")\n",
    "            return path\n",
    "\n",
    "    return \"No solution found.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create solvable puzzle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "RANDOMIZE_STEPS = 100_000\n",
    "state = goal_state.copy()\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "while not is_solvable(state):\n",
    "    state = make_solvable(state)\n",
    "\n",
    "print(\"Solvable puzzle generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which algorithm to run?\n",
    "RUN = 'Dijkstra'  # 'A*' or 'Dijkstra'\n",
    "# Solve the puzzle\n",
    "switch = {\n",
    "    'A*': search_astar,\n",
    "    'Dijkstra': search_astar\n",
    "}\n",
    "use_heuristic = True\n",
    "if RUN == 'Dijkstra':\n",
    "    use_heuristic = False\n",
    "\n",
    "HEURISTIC = 'linear_conflict_manhattan'\n",
    "switch_heuristic = {\n",
    "    'manhattan': manhattan,\n",
    "    'hamming': hamming,\n",
    "    'linear_conflict_manhattan': linear_conflict_manhattan\n",
    "}\n",
    "heuristic = switch_heuristic[HEURISTIC]\n",
    "\n",
    "# Test for state 2 8 7 3 6 5 0 1 4\n",
    "state = np.array([[2, 8, 7], [3, 6, 5], [0, 1, 4]])\n",
    "\n",
    "\n",
    "solve_puzzle = switch[RUN]\n",
    "solution = solve_puzzle(state, goal_state, heuristic, HEURISTIC)\n",
    "print(\"Initial state:\")\n",
    "print(state)\n",
    "print(\"\\nSolution steps:\")\n",
    "if isinstance(solution, list):\n",
    "    for act in solution:\n",
    "        print(act.pos1, '->', act.pos2)\n",
    "else:\n",
    "    print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-QFw0xGYb-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
